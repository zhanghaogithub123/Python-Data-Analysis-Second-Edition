{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Analytics and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rain mean 2.179195942665883\n",
      "Rain variance 18.803443919014683\n",
      "Anderson rain AndersonResult(statistic=5731.267850009339, critical_values=array([0.576, 0.656, 0.787, 0.918, 1.092]), significance_level=array([15. , 10. ,  5. ,  2.5,  1. ]))\n",
      "Scaled mean 3.4130160280768244e-17\n",
      "Scaled variance 1.0\n",
      "Anderson scaled AndersonResult(statistic=5731.267850009339, critical_values=array([0.576, 0.656, 0.787, 0.918, 1.092]), significance_level=array([15. , 10. ,  5. ,  2.5,  1. ]))\n",
      "[0. 1.] 24594.0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 42 43 44 45 46 47 48\n",
      " 49 50 52 53 55 58 61 62]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import anderson\n",
    "\n",
    "rain = np.load('rain.npy')\n",
    "rain = .1 * rain\n",
    "rain[rain < 0] = .05/2\n",
    "print(\"Rain mean\", rain.mean())\n",
    "print(\"Rain variance\", rain.var())\n",
    "print(\"Anderson rain\", anderson(rain))\n",
    "\n",
    "scaled = preprocessing.scale(rain)\n",
    "print(\"Scaled mean\", scaled.mean())\n",
    "print(\"Scaled variance\", scaled.var())\n",
    "print(\"Anderson scaled\", anderson(scaled))\n",
    "\n",
    "binarized = preprocessing.binarize(rain.reshape(-1,1))\n",
    "print(np.unique(binarized), binarized.sum())\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(rain.astype(int))\n",
    "print(lb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5767262564769428\n",
      "Accuracy:  0.4133333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "def classify(x, y):\n",
    "    clf = LogisticRegression(random_state=12)\n",
    "    scores = []\n",
    "    kf = KFold(n_splits=10)\n",
    "    for train,test in kf.split(x):\n",
    "      clf.fit(x[train], y[train])\n",
    "      scores.append(clf.score(x[test], y[test]))\n",
    "\n",
    "    print(\"Accuracy: \",np.mean(scores))\n",
    "\n",
    "rain = np.load('rain.npy')\n",
    "dates = np.load('doy.npy')\n",
    "\n",
    "x = np.vstack((dates[:-1], rain[:-1]))\n",
    "y = np.sign(rain[1:])\n",
    "classify(x.T, y)\n",
    "\n",
    "#iris example\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data[:, :2]\n",
    "y = iris.target\n",
    "classify(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5596606878225765\n",
      "{'mean_fit_time': array([0.16861645, 0.04375688, 0.35352627, 0.07613405, 0.08480851,\n",
      "       0.35848077]),\n",
      " 'mean_score_time': array([0.05645959, 0.00872914, 0.18407234, 0.04106633, 0.01766825,\n",
      "       0.24382901]),\n",
      " 'mean_test_score': array([0.42879043, 0.55570034, 0.36938525, 0.30658184, 0.41673054,\n",
      "       0.49195156]),\n",
      " 'mean_train_score': array([0.43378363, 0.55600709, 0.37209364, 0.30101084, 0.41388724,\n",
      "       0.49604207]),\n",
      " 'param_C': masked_array(data=[1, 1, 1, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_kernel': masked_array(data=['linear', 'poly', 'rbf', 'linear', 'poly', 'rbf'],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'C': 1, 'kernel': 'linear'},\n",
      "            {'C': 1, 'kernel': 'poly'},\n",
      "            {'C': 1, 'kernel': 'rbf'},\n",
      "            {'C': 10, 'kernel': 'linear'},\n",
      "            {'C': 10, 'kernel': 'poly'},\n",
      "            {'C': 10, 'kernel': 'rbf'}],\n",
      " 'rank_test_score': array([3, 1, 5, 6, 4, 2], dtype=int32),\n",
      " 'split0_test_score': array([0.28374339, 0.55966889, 0.36767073, 0.2874224 , 0.55966889,\n",
      "       0.55759945]),\n",
      " 'split0_train_score': array([0.29469932, 0.55965659, 0.37215898, 0.27921505, 0.55965659,\n",
      "       0.56122801]),\n",
      " 'split1_test_score': array([0.55963514, 0.55963514, 0.37168481, 0.28292197, 0.55963514,\n",
      "       0.55227656]),\n",
      " 'split1_train_score': array([0.55967346, 0.55967346, 0.37340947, 0.26889468, 0.55967346,\n",
      "       0.55480607]),\n",
      " 'split2_test_score': array([0.44300498, 0.54779609, 0.36880031, 0.3494059 , 0.13085473,\n",
      "       0.36596397]),\n",
      " 'split2_train_score': array([0.44697812, 0.54869122, 0.37071245, 0.35492278, 0.12233166,\n",
      "       0.37209213]),\n",
      " 'std_fit_time': array([0.03045226, 0.00640013, 0.05637059, 0.01121556, 0.01103908,\n",
      "       0.07196245]),\n",
      " 'std_score_time': array([0.0041763 , 0.00483962, 0.01916766, 0.01037262, 0.00962258,\n",
      "       0.0184669 ]),\n",
      " 'std_test_score': array([0.11308202, 0.00558885, 0.00169016, 0.03033514, 0.2021331 ,\n",
      "       0.08910806]),\n",
      " 'std_train_score': array([0.10857684, 0.00517311, 0.00110202, 0.03835362, 0.20616093,\n",
      "       0.08768505])}\n",
      "Accuracy:  0.82\n",
      "{'mean_fit_time': array([0.00095661, 0.00085894, 0.00102917, 0.00071486, 0.00064866,\n",
      "       0.00077327]),\n",
      " 'mean_score_time': array([0.00060105, 0.00051483, 0.00061933, 0.00045244, 0.00050672,\n",
      "       0.0004499 ]),\n",
      " 'mean_test_score': array([0.8       , 0.58666667, 0.8       , 0.74666667, 0.56666667,\n",
      "       0.79333333]),\n",
      " 'mean_train_score': array([0.80372351, 0.63111507, 0.80709051, 0.77104377, 0.63101604,\n",
      "       0.79708853]),\n",
      " 'param_C': masked_array(data=[1, 1, 1, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_kernel': masked_array(data=['linear', 'poly', 'rbf', 'linear', 'poly', 'rbf'],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'C': 1, 'kernel': 'linear'},\n",
      "            {'C': 1, 'kernel': 'poly'},\n",
      "            {'C': 1, 'kernel': 'rbf'},\n",
      "            {'C': 10, 'kernel': 'linear'},\n",
      "            {'C': 10, 'kernel': 'poly'},\n",
      "            {'C': 10, 'kernel': 'rbf'}],\n",
      " 'rank_test_score': array([1, 5, 1, 4, 6, 3], dtype=int32),\n",
      " 'split0_test_score': array([0.74509804, 0.74509804, 0.76470588, 0.76470588, 0.74509804,\n",
      "       0.74509804]),\n",
      " 'split0_train_score': array([0.82828283, 0.82828283, 0.83838384, 0.82828283, 0.82828283,\n",
      "       0.83838384]),\n",
      " 'split1_test_score': array([0.82352941, 0.56862745, 0.84313725, 0.82352941, 0.50980392,\n",
      "       0.82352941]),\n",
      " 'split1_train_score': array([0.81818182, 0.54545455, 0.81818182, 0.81818182, 0.53535354,\n",
      "       0.7979798 ]),\n",
      " 'split2_test_score': array([0.83333333, 0.4375    , 0.79166667, 0.64583333, 0.4375    ,\n",
      "       0.8125    ]),\n",
      " 'split2_train_score': array([0.76470588, 0.51960784, 0.76470588, 0.66666667, 0.52941176,\n",
      "       0.75490196]),\n",
      " 'std_fit_time': array([1.07092207e-04, 7.97866349e-05, 3.51489331e-05, 1.71262703e-04,\n",
      "       1.56708711e-05, 3.81550846e-05]),\n",
      " 'std_score_time': array([8.25376058e-05, 6.23339842e-05, 9.53090675e-05, 1.12817148e-04,\n",
      "       3.32519611e-05, 1.03394160e-05]),\n",
      " 'std_test_score': array([0.0396059 , 0.12555888, 0.03283948, 0.0732999 , 0.13138901,\n",
      "       0.03490884]),\n",
      " 'std_train_score': array([0.02789611, 0.1398174 , 0.03108454, 0.07392087, 0.13950977,\n",
      "       0.03408716])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/vivoadmin/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from pprint import PrettyPrinter\n",
    "\n",
    "def classify(x, y):\n",
    "    clf = GridSearchCV(SVC(random_state=42, max_iter=100), {'kernel': ['linear', 'poly', 'rbf'], 'C':[1, 10]})\n",
    "    clf.fit(x, y)\n",
    "    print(\"Accuracy: \", clf.score(x, y))\n",
    "    PrettyPrinter().pprint(clf.cv_results_)\n",
    "\n",
    "rain = np.load('rain.npy')\n",
    "dates = np.load('doy.npy')\n",
    "\n",
    "x = np.vstack((dates[:-1], rain[:-1]))\n",
    "y = np.sign(rain[1:])\n",
    "\n",
    "classify(x.T, y)\n",
    "\n",
    "#iris example\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data[:, :2]\n",
    "y = iris.target\n",
    "classify(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 0.052783876094198205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0e0aa440b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 0.6831439034550796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0e08a9e320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def regress(x, y, title):\n",
    "    clf = ElasticNetCV(max_iter=200, cv=10, l1_ratio = [.1, .5, \n",
    ".7, .9, .95, .99, 1])\n",
    "\n",
    "    clf.fit(x, y)\n",
    "    print(\"Score\", clf.score(x, y))\n",
    "\n",
    "    pred = clf.predict(x)\n",
    "    plt.title(\"Scatter plot of prediction and \" + title)\n",
    "    plt.xlabel(\"Prediction\")\n",
    "    plt.ylabel(\"Target\")\n",
    "    plt.scatter(y, pred)\n",
    "    # Show perfect fit line\n",
    "    if \"Boston\" in title:\n",
    "        plt.plot(y, y, label=\"Perfect Fit\")\n",
    "        plt.legend()\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "rain = .1 * np.load('rain.npy')\n",
    "rain[rain < 0] = .05/2\n",
    "dates = np.load('doy.npy')\n",
    "\n",
    "x = np.vstack((dates[:-1], rain[:-1]))\n",
    "y = rain[1:]\n",
    "regress(x.T, y, \"rain data\")\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "x = boston.data\n",
    "y = boston.target\n",
    "regress(x, y, \"Boston house prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import preprocessing\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def regress(x, y, ncpus, title):\n",
    "    X = preprocessing.scale(x)\n",
    "    Y = preprocessing.scale(y)\n",
    "    clf = SVR(max_iter=ncpus * 200)\n",
    "\n",
    "    train_sizes, train_scores, test_scores = learning_curve(clf, X, Y, n_jobs=ncpus) \n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.plot(train_sizes, train_scores.mean(axis=1), label=\"Train score\")\n",
    "    plt.plot(train_sizes, test_scores.mean(axis=1), '--', label=\"Test score\")\n",
    "    print(\"Max test score \" + title, test_scores.max())\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "rain = .1 * np.load('rain.npy')\n",
    "rain[rain < 0] = .05/2\n",
    "dates = np.load('doy.npy')\n",
    "\n",
    "x = np.vstack((dates[:-1], rain[:-1]))\n",
    "y = rain[1:]\n",
    "ncpus = multiprocessing.cpu_count()\n",
    "regress(x.T, y, ncpus, \"Rain\")\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "x = boston.data\n",
    "y = boston.target\n",
    "regress(x, y, ncpus, \"Boston\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with affinity propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import cluster\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import euclidean_distances\n",
    "\n",
    "x, _ = datasets.make_blobs(n_samples=100, centers=3, n_features=2, \n",
    "random_state=10)\n",
    "S = euclidean_distances(x)\n",
    "\n",
    "aff_pro = cluster.AffinityPropagation().fit(S)\n",
    "labels = aff_pro.labels_\n",
    "\n",
    "styles = ['o', 'x', '^']\n",
    "\n",
    "for style, label in zip(styles, np.unique(labels)):\n",
    "   print(label)\n",
    "   plt.plot(x[labels == label], style, label=label)\n",
    "plt.title(\"Clustering Blobs\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import cluster\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "rain = .1 * np.load('rain.npy')\n",
    "rain[rain < 0] = .05/2\n",
    "dates = np.load('doy.npy')\n",
    "x = np.vstack((dates, rain))\n",
    "df = pd.DataFrame.from_records(x.T, columns=['dates', 'rain'])\n",
    "df = df.groupby('dates').mean()\n",
    "df.plot()\n",
    "x = np.vstack((np.arange(1, len(df) + 1) , \n",
    "df.as_matrix().ravel()))\n",
    "x = x.T\n",
    "ms = cluster.MeanShift()\n",
    "ms.fit(x)\n",
    "labels = ms.predict(x)\n",
    "\n",
    "plt.figure()\n",
    "grays = ['0', '0.5', '0.75']\n",
    "\n",
    "for gray, label in zip(grays, np.unique(labels)):\n",
    "    match = labels == label\n",
    "    x0 = x[:, 0]\n",
    "    x1 = x[:, 1]\n",
    "    plt.plot(x0[match], x1[match], lw=label+1, label=label)\n",
    "    plt.fill_between(x0, x1, where=match, color=gray)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array\n",
    "import random\n",
    "import numpy as np\n",
    "from deap import algorithms\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from scipy.stats import shapiro\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", array.array, typecode='d', \n",
    "fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_float\", random.random)\n",
    "toolbox.register(\"individual\", tools.initRepeat, \n",
    "creator.Individual, toolbox.attr_float, 200)\n",
    "toolbox.register(\"populate\", tools.initRepeat, list, \n",
    "toolbox.individual)\n",
    "\n",
    "def eval(individual):\n",
    "    return shapiro(individual)[1],\n",
    "\n",
    "toolbox.register(\"evaluate\", eval)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.1)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=4)\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "pop = toolbox.populate(n=400)\n",
    "hof = tools.HallOfFame(1)\n",
    "stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
    "stats.register(\"max\", np.max)\n",
    "\n",
    "algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=80, \n",
    "stats=stats, halloffame=hof)\n",
    "\n",
    "print(shapiro(hof[0])[1])\n",
    "plt.hist(hof[0])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theanets\n",
    "import multiprocessing\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rain = .1 * np.load('rain.npy')\n",
    "rain[rain < 0] = .05/2\n",
    "dates = np.load('doy.npy')\n",
    "x = np.vstack((dates[:-1], np.sign(rain[:-1])))\n",
    "x = x.T\n",
    "\n",
    "y = np.vstack(np.sign(rain[1:]),)\n",
    "N = int(.9 * len(x))\n",
    "\n",
    "train = [x[:N], y[:N]]\n",
    "valid = [x[N:], y[N:]]\n",
    "\n",
    "net = theanets.Regressor(layers=[2,3,1])\n",
    "\n",
    "net.train(train,valid,learning_rate=0.1,momentum=0.5)\n",
    "\n",
    "pred = net.predict(x[N:]).ravel()\n",
    "print(\"Pred Min\", pred.min(), \"Max\", pred.max())\n",
    "print(\"Y Min\", y.min(), \"Max\", y.max())\n",
    "print(\"Accuracy\", accuracy_score(y[N:], pred >= .5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "import pydotplus as pydot\n",
    "import io\n",
    "import numpy as np\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "rain = .1 * np.load('rain.npy')\n",
    "rain[rain < 0] = .05/2\n",
    "dates = np.load('doy.npy').astype(int)\n",
    "x = np.vstack((dates[:-1], np.sign(rain[:-1])))\n",
    "x = x.T\n",
    "\n",
    "y = np.sign(rain[1:])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "random_state=37)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(random_state=37)\n",
    "params = {\"max_depth\": [2, None],\n",
    "              \"min_samples_leaf\": sp_randint(1, 5),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "rscv = RandomizedSearchCV(clf, params)\n",
    "rscv.fit(x_train,y_train)\n",
    "\n",
    "sio = io.StringIO()\n",
    "tree.export_graphviz(rscv.best_estimator_, out_file=sio, \n",
    "feature_names=['day-of-year','yest'])\n",
    "dec_tree = pydot.graph_from_dot_data(sio.getvalue())\n",
    "\n",
    "with NamedTemporaryFile(prefix='rain', suffix='.png', \n",
    "delete=False) as f:\n",
    "    dec_tree.write_png(f.name)\n",
    "    print(\"Written figure to\", f.name)\n",
    "\n",
    "print(\"Best Train Score\", rscv.best_score_)\n",
    "print(\"Test Score\", rscv.score(x_test, y_test))\n",
    "print(\"Best params\", rscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
